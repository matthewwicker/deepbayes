{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a BNN with 20 lines of code in 20 seconds\n",
    "\n",
    "### In this notebook we demonstrate how simple it is to perform approximate inference using DeepBayes\n",
    "\n",
    "(Time reported from a M1 Pro Macbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\deepbayes\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\deepbayes\\lib\\site-packages\\tensorflow_probability-0.23.0-py3.10.egg\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\deepbayes\\lib\\site-packages\\tensorflow_probability-0.23.0-py3.10.egg\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import deepbayes\n",
    "import deepbayes.optimizers as optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we load in and normalize the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 784)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255.\n",
    "X_train = X_train.astype(\"float32\").reshape(-1, 1, 28*28)\n",
    "X_test = X_test.astype(\"float32\").reshape(-1, 1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We define a model using the flexible Keras interface\n",
    "(Most valid Keras models are also valid DeepBayes models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\deepbayes\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation=\"relu\", input_shape=(1, 28*28)))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then select the inference method and key parameters for a run\n",
    "Calling compile will set up the DeepBayes model\n",
    "\n",
    "Calling train will then perform inference over the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This optimizer does not have a default compilation method. Please make sure to call the correct .compile method before use.\n",
      "BayesKeras: Using implicit prior\n",
      "(784, 128) 0.03571428571428571\n",
      "(128, 10) 0.08838834764831845\n",
      "BayesKeras: Using implicit prior\n",
      "(784, 128) 0.03571428571428571\n",
      "(128, 10) 0.08838834764831845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:13<00:00, 35.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.816, acc: 0.105, val_loss: 0.659, val_acc: 0.104\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\tmp\\\\BayesKeras.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m opt \u001b[38;5;241m=\u001b[39m optimizers\u001b[38;5;241m.\u001b[39mVariationalOnlineGuassNewton()\n\u001b[0;32m      3\u001b[0m bayes_model \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mcompile(model, loss_fn\u001b[38;5;241m=\u001b[39mloss, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mbayes_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\deepbayes\\lib\\site-packages\\deepbayes-0.1.0-py3.10.egg\\deepbayes\\optimizers\\blrvi.py:169\u001b[0m, in \u001b[0;36mVariationalOnlineGuassNewton.train\u001b[1;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_train, y_train, X_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\deepbayes\\lib\\site-packages\\deepbayes-0.1.0-py3.10.egg\\deepbayes\\optimizers\\optimizer.py:104\u001b[0m, in \u001b[0;36mOptimizer.train\u001b[1;34m(self, X_train, y_train, X_test, y_test, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m (loss, acc) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;241m.\u001b[39mresult(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_metric\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    103\u001b[0m (val_loss, val_acc) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_loss\u001b[38;5;241m.\u001b[39mresult(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_metric\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Clear the current state of the metrics\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;241m.\u001b[39mreset_states(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_metric\u001b[38;5;241m.\u001b[39mreset_states()\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\deepbayes\\lib\\site-packages\\deepbayes-0.1.0-py3.10.egg\\deepbayes\\optimizers\\optimizer.py:169\u001b[0m, in \u001b[0;36mOptimizer.logging\u001b[1;34m(self, loss, acc, val_loss, val_acc, epoch)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mprint\u001b[39m (template\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, loss,\n\u001b[0;32m    165\u001b[0m                  acc,\n\u001b[0;32m    166\u001b[0m                  val_loss,\n\u001b[0;32m    167\u001b[0m                  val_acc, rob, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon))\n\u001b[0;32m    168\u001b[0m log_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Train: [Loss: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m, Acc: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m], Test: [Loss: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m, Acc: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 169\u001b[0m \u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasicConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEBUG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(log_template\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, loss, acc, val_loss, val_acc))\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\deepbayes\\lib\\logging\\__init__.py:2040\u001b[0m, in \u001b[0;36mbasicConfig\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m   2038\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2039\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m-> 2040\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mFileHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2041\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2042\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2043\u001b[0m     stream \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\deepbayes\\lib\\logging\\__init__.py:1169\u001b[0m, in \u001b[0;36mFileHandler.__init__\u001b[1;34m(self, filename, mode, encoding, delay, errors)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m     StreamHandler\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\deepbayes\\lib\\logging\\__init__.py:1201\u001b[0m, in \u001b[0;36mFileHandler._open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;124;03mOpen the current base file with the (original) mode and encoding.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124;03mReturn the resulting stream.\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m open_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_builtin_open\n\u001b[1;32m-> 1201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbaseFilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\tmp\\\\BayesKeras.log'"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.35; decay=0.0\n",
    "opt = optimizers.VariationalOnlineGuassNewton()\n",
    "bayes_model = opt.compile(model, loss_fn=loss, epochs=5, learning_rate=learning_rate, batch_size=128)\n",
    "bayes_model.train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, we can save the resulting posterior. This will create a new directory and store all the posterior information for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_model.save(\"PosteriorModels/VOGN_MNIST_Posterior\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
